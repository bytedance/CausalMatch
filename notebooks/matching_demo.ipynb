{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b167bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Library/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/Users/bytedance/Library/Python/3.12/lib/python/site-packages', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages']\n",
      "current version is:  0.0.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('/Users/bytedance/PycharmProjects/github/CausalMatch')\n",
    "import causalmatch as causalmatch\n",
    "from causalmatch import matching,gen_test_data\n",
    "\n",
    "print('current version is: ',causalmatch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd640ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score,roc_auc_score,f1_score\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50ea99",
   "metadata": {},
   "source": [
    "# 1. generate pseudo data for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ccbd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_test_data(n = 10000, c_ratio=0.5)\n",
    "df.head()\n",
    "\n",
    "\n",
    "X = ['c_1', 'c_2', 'c_3', 'd_1', 'gender']\n",
    "y = ['y', 'y2']\n",
    "id = 'user_id'\n",
    "\n",
    "# ------ 实验变量必须是二分类0,1变量  ------ #\n",
    "T = 'treatment'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d9035",
   "metadata": {},
   "source": [
    "# 2. PSM Demo\n",
    "##  2.1 Simple PSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62795d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dataframe columns Index(['user_id', 'treatment', 'pscore'], dtype='object')\n",
      "                  0         1\n",
      "const     -1.171885  0.034522\n",
      "treatment  0.480457  0.085681\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: initialize matching object\n",
    "match_obj = matching(data = df,     \n",
    "                     T = T,\n",
    "                     X = X,\n",
    "                     id = id)\n",
    "\n",
    "# STEP 2: propensity score matching\n",
    "\n",
    "match_obj.psm(n_neighbors = 1,  # number of neighbors\n",
    "              model = GradientBoostingClassifier(), # p-score model\n",
    "              trim_percentage = 0.1, # trim X% of pscore, if equals 0.1 then trim min 5% and max 5%\n",
    "              caliper = 0.1) # p-score diff must be smaller than or equal to the caliper value\n",
    "\n",
    "# # if you with to keep all matched observations\n",
    "# match_obj.psm(n_neighbors = 1, \n",
    "#               model = GradientBoostingClassifier(), \n",
    "#               trim_percentage = 0, \n",
    "#               caliper = 1) \n",
    "\n",
    "\n",
    "# STEP 3: balance check after propensity score matching\n",
    "match_obj.balance_check(include_discrete = True)\n",
    "\n",
    "\n",
    "# STEP 4: get result - pandas df, and merge X and y back to original data\n",
    "print('Output dataframe columns', match_obj.df_out_final_post_trim.columns)\n",
    "df_out = match_obj.df_out_final_post_trim.merge(df[y + X + [id]], how='left', on = id)\n",
    "\n",
    "# STEP 5: calculate average treatment effect \n",
    "\n",
    "X_mat = df_out[T]\n",
    "y_mat = df_out[y]\n",
    "\n",
    "X_mat = sm.add_constant(X_mat)\n",
    "model = sm.OLS(y_mat,X_mat)\n",
    "results = model.fit()\n",
    "print(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55cd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5097577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a234cf19",
   "metadata": {},
   "source": [
    "# 2.2 PSM with multiple p-score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a96946e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4077, number of negative: 3923\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 791\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509625 -> initscore=0.038505\n",
      "[LightGBM] [Info] Start training from score 0.038505\n",
      "The f1 score for all models you specify is: [0.5773809523809523, 0.5805354866128347, 0.6130055511498811, 0.5143134400776322, 0.5076242006886375, 0.5004793863854267, 0.5656050955414013, 0.5198863636363636, 0.5149928605425987]\n",
      "The best model is the 2 model\n",
      "       Covariates  Mean Treated  Mean Control   SMD  Var Ratio  ks-p_val  \\\n",
      "0             c_1        0.5004        0.4999  0.00       1.03     0.176   \n",
      "1             c_2        0.5024        0.5040 -0.01       0.98     0.684   \n",
      "2             c_3        0.5033        0.5033  0.00       0.98     0.667   \n",
      "3         d_1_bee        0.1124        0.1122  0.00        NaN     1.000   \n",
      "4         d_1_cat        0.1581        0.1579  0.00        NaN     1.000   \n",
      "5         d_1_dog        0.1929        0.1868  0.02        NaN     1.000   \n",
      "6        d_1_pear        0.2551        0.2670 -0.03        NaN     0.854   \n",
      "7     gender_cat1        0.0714        0.0724 -0.00        NaN     1.000   \n",
      "8     gender_cat2        0.0883        0.0865  0.01        NaN     1.000   \n",
      "9     gender_cat3        0.1683        0.1664  0.01        NaN     1.000   \n",
      "10    gender_cat4        0.0247        0.0247  0.00        NaN     1.000   \n",
      "11    gender_cat5        0.1156        0.1165 -0.00        NaN     1.000   \n",
      "12     gender_dog        0.1776        0.1848 -0.02        NaN     0.999   \n",
      "13  gender_female        0.2046        0.1982  0.02        NaN     1.000   \n",
      "14    gender_male        0.0263        0.0263  0.00        NaN     1.000   \n",
      "15     gender_pig        0.0736        0.0757 -0.01        NaN     1.000   \n",
      "\n",
      "    ttest-p_val  \n",
      "0         0.928  \n",
      "1         0.783  \n",
      "2         1.000  \n",
      "3         0.975  \n",
      "4         0.978  \n",
      "5         0.434  \n",
      "6         0.169  \n",
      "7         0.848  \n",
      "8         0.752  \n",
      "9         0.791  \n",
      "10        1.000  \n",
      "11        0.877  \n",
      "12        0.341  \n",
      "13        0.415  \n",
      "14        1.000  \n",
      "15        0.679  \n",
      "Output dataframe columns Index(['user_id', 'treatment', 'pscore'], dtype='object')\n",
      "                  0         1\n",
      "const     -1.195507  0.008059\n",
      "treatment  0.504235  0.103476\n"
     ]
    }
   ],
   "source": [
    "# STEP 0: 第零步，定义好所有你需要用到的模型\n",
    "ps_model1 = LogisticRegression(C=1e6)\n",
    "ps_model2 = SVC(probability=True)\n",
    "ps_model3 = GaussianNB()\n",
    "ps_model4 = KNeighborsClassifier()\n",
    "ps_model5 = DecisionTreeClassifier()\n",
    "ps_model6 = RandomForestClassifier()\n",
    "ps_model7 = GradientBoostingClassifier()\n",
    "ps_model8 = LGBMClassifier()\n",
    "ps_model9 = XGBClassifier()\n",
    "\n",
    "\n",
    "# we chooise model with best f1 score\n",
    "model_list = [ps_model1, ps_model2, ps_model3, \n",
    "              ps_model4, ps_model5, ps_model6, \n",
    "              ps_model7, ps_model8, ps_model9]\n",
    "\n",
    "\n",
    "# STEP 1: 第一步，初始化；initialize matching object\n",
    "match_obj = matching(data = df,     \n",
    "                     T = T,\n",
    "                     X = X,\n",
    "                     id = id)\n",
    "\n",
    "# STEP 2: 第二步，倾向性得分匹配；propensity score matching\n",
    "match_obj.psm(n_neighbors = 1,\n",
    "              model_list = model_list, # input list of models you want to try\n",
    "              trim_percentage = 0,\n",
    "              caliper = 1,              \n",
    "              test_size = 0.2) # train-test split, what portion does test sample takes\n",
    "\n",
    "\n",
    "\n",
    "# STEP 3: 第三步，匹配后的平衡性检验；balance check after propensity score matching\n",
    "print(match_obj.balance_check(include_discrete = True))\n",
    "\n",
    "\n",
    "# STEP 4: 第四步，求ATE\n",
    "print('Output dataframe columns', match_obj.df_out_final_post_trim.columns)\n",
    "df_out = match_obj.df_out_final_post_trim.merge(df[y + X + [id]], how='left', on = id)\n",
    "\n",
    "X_mat = df_out[T]\n",
    "y_mat = df_out[y]\n",
    "\n",
    "X_mat = sm.add_constant(X_mat)\n",
    "model = sm.OLS(y_mat,X_mat)\n",
    "results = model.fit()\n",
    "print(results.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d16be",
   "metadata": {},
   "source": [
    "## 2.3 PSM with ATE generated for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76692a8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# STEP 0: 第零步，定义好所有你需要用到的模型\n",
    "ps_model1 = LogisticRegression(C=1e6)\n",
    "ps_model2 = SVC(probability=True)\n",
    "ps_model3 = GaussianNB()\n",
    "ps_model4 = KNeighborsClassifier()\n",
    "ps_model5 = DecisionTreeClassifier()\n",
    "ps_model6 = RandomForestClassifier()\n",
    "ps_model7 = GradientBoostingClassifier()\n",
    "ps_model8 = LGBMClassifier()\n",
    "ps_model9 = XGBClassifier()\n",
    "\n",
    "\n",
    "# we chooise model with best f1 score\n",
    "model_list = [ps_model1, ps_model2]\n",
    "\n",
    "\n",
    "# STEP 1: 第一步，初始化；initialize matching object\n",
    "match_obj = matching(data = df,     \n",
    "                     T = T,\n",
    "                     X = X,\n",
    "                     y = y, # you have to identify dependent variable name if want to use ATE function\n",
    "                     id = id)\n",
    "\n",
    "# STEP 2: 第二步，倾向性得分匹配；propensity score matching\n",
    "match_obj.psm(n_neighbors = 1,\n",
    "              model = LogisticRegression(C=1e6), # input list of models you want to try\n",
    "              trim_percentage = 0,\n",
    "              caliper = 1,              \n",
    "              test_size = 0.2) # train-test split, what portion does test sample takes\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fa067e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Covariates  Mean Treated  Mean Control   SMD  Var Ratio  ks-p_val  \\\n",
      "0             c_1        0.5004        0.4984  0.01       1.00     0.058   \n",
      "1             c_2        0.5024        0.5027 -0.00       1.01     0.504   \n",
      "2             c_3        0.5033        0.5031  0.00       0.99     0.766   \n",
      "3         d_1_bee        0.1124        0.1034  0.03        NaN     0.984   \n",
      "4         d_1_cat        0.1581        0.1727 -0.04        NaN     0.651   \n",
      "5         d_1_dog        0.1929        0.1878  0.01        NaN     1.000   \n",
      "6        d_1_pear        0.2551        0.2466  0.02        NaN     0.993   \n",
      "7     gender_cat1        0.0714        0.0667  0.02        NaN     1.000   \n",
      "8     gender_cat2        0.0883        0.0963 -0.03        NaN     0.996   \n",
      "9     gender_cat3        0.1683        0.1752 -0.02        NaN     1.000   \n",
      "10    gender_cat4        0.0247        0.0290 -0.03        NaN     1.000   \n",
      "11    gender_cat5        0.1156        0.1279 -0.04        NaN     0.826   \n",
      "12     gender_dog        0.1776        0.1695  0.02        NaN     0.996   \n",
      "13  gender_female        0.2046        0.1923  0.03        NaN     0.826   \n",
      "14    gender_male        0.0263        0.0241  0.01        NaN     1.000   \n",
      "15     gender_pig        0.0736        0.0783 -0.02        NaN     1.000   \n",
      "\n",
      "    ttest-p_val  \n",
      "0         0.724  \n",
      "1         0.967  \n",
      "2         0.965  \n",
      "3         0.142  \n",
      "4         0.049  \n",
      "5         0.512  \n",
      "6         0.326  \n",
      "7         0.349  \n",
      "8         0.161  \n",
      "9         0.358  \n",
      "10        0.178  \n",
      "11        0.056  \n",
      "12        0.284  \n",
      "13        0.118  \n",
      "14        0.487  \n",
      "15        0.370  \n",
      "    y       ate          p_val\n",
      "0   y  0.502627  5.525199e-121\n",
      "1  y2  0.104296   1.281648e-07\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: 第三步，匹配后的平衡性检验；balance check after propensity score matching\n",
    "print(match_obj.balance_check(include_discrete = True))\n",
    "\n",
    "\n",
    "# STEP 4: 第四步，求ATE\n",
    "print(match_obj.ate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fefb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa75bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25cb9aba",
   "metadata": {},
   "source": [
    "# 3. CEM\n",
    "## 3.1 Simple CEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d98668",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of matched obs (9768, 15) number of total obs  (10000, 15)\n",
      "   Covariates  Mean Treated  Mean Control   SMD  Var Ratio  ks-p_val  \\\n",
      "0         c_1        0.4999        0.4983  0.01       0.99     0.445   \n",
      "1     d_1_bee        0.1114        0.1194 -0.03        NaN     0.997   \n",
      "2     d_1_cat        0.1546        0.1570 -0.01        NaN     1.000   \n",
      "3     d_1_dog        0.1929        0.2002 -0.02        NaN     0.999   \n",
      "4    d_1_pear        0.2588        0.2545  0.01        NaN     1.000   \n",
      "5     d_3_1.0        0.2039        0.1882  0.04        NaN     0.573   \n",
      "6     d_3_2.0        0.0516        0.0516  0.00        NaN     1.000   \n",
      "7     d_3_3.0        0.1790        0.1804 -0.00        NaN     1.000   \n",
      "8     d_3_4.0        0.0704        0.0713 -0.00        NaN     1.000   \n",
      "9     d_3_5.0        0.0692        0.0676  0.01        NaN     1.000   \n",
      "10    d_3_6.0        0.0921        0.0938 -0.01        NaN     1.000   \n",
      "11    d_3_7.0        0.1824        0.1835 -0.00        NaN     1.000   \n",
      "12    d_3_8.0        0.0221        0.0211  0.01        NaN     1.000   \n",
      "13    d_3_9.0        0.1063        0.1140 -0.02        NaN     0.998   \n",
      "\n",
      "    ttest-p_val  \n",
      "0         0.789  \n",
      "1         0.217  \n",
      "2         0.738  \n",
      "3         0.359  \n",
      "4         0.627  \n",
      "5         0.050  \n",
      "6         1.000  \n",
      "7         0.854  \n",
      "8         0.875  \n",
      "9         0.748  \n",
      "10        0.780  \n",
      "11        0.896  \n",
      "12        0.728  \n",
      "13        0.219  \n",
      "   y       ate          p_val\n",
      "0  y  0.512274  7.780753e-120\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: 第一步，初始化；initialize matching object\n",
    "match_obj_cem = matching(data = df, \n",
    "                       y = ['y'],\n",
    "                       T = 'treatment', \n",
    "                       X = ['c_1','d_1','d_3'],\n",
    "                       id = 'user_id')\n",
    "\n",
    "# STEP 2：第二步，粗粒度匹配；coarsened exact matching\n",
    "match_obj_cem.cem(n_bins = 10, \n",
    "                  k2k = True) # k2k: 如果匹配出的结果是实验组样本N1>对照组N2，在实验组样本中随机抽样N2个对照组样本，使得样本数均衡\n",
    "\n",
    "\n",
    "# STEP 3: 第三步，匹配后的平衡性检验；balance check after CEM\n",
    "print(match_obj_cem.balance_check(include_discrete=True))\n",
    "\n",
    "# STEP 4: 第四步，计算ATE\n",
    "print(match_obj_cem.ate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a6679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bf922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a7267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc3c85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245a466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a16ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c125836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf83e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd408f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a24152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f551745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5f437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d5f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8dd7111",
   "metadata": {},
   "source": [
    "## 3.2 CEM with customized bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94bab763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of matched obs (9806, 15) number of total obs  (10000, 15)\n",
      "   Covariates  Mean Treated  Mean Control   SMD  Var Ratio  ks-p_val  \\\n",
      "0         c_1        0.5002        0.4984  0.01       0.99     0.433   \n",
      "1     d_1_bee        0.1103        0.1201 -0.03        NaN     0.971   \n",
      "2     d_1_cat        0.1575        0.1577 -0.00        NaN     1.000   \n",
      "3     d_1_dog        0.1934        0.1997 -0.02        NaN     1.000   \n",
      "4    d_1_pear        0.2549        0.2541  0.00        NaN     1.000   \n",
      "5     d_3_1.0        0.2025        0.1874  0.04        NaN     0.626   \n",
      "6     d_3_2.0        0.0512        0.0514 -0.00        NaN     1.000   \n",
      "7     d_3_3.0        0.1783        0.1797 -0.00        NaN     1.000   \n",
      "8     d_3_4.0        0.0706        0.0710 -0.00        NaN     1.000   \n",
      "9     d_3_5.0        0.0687        0.0673  0.01        NaN     1.000   \n",
      "10    d_3_6.0        0.0930        0.0934 -0.00        NaN     1.000   \n",
      "11    d_3_7.0        0.1813        0.1827 -0.00        NaN     1.000   \n",
      "12    d_3_8.0        0.0247        0.0226  0.01        NaN     1.000   \n",
      "13    d_3_9.0        0.1050        0.1136 -0.03        NaN     0.993   \n",
      "\n",
      "    ttest-p_val  \n",
      "0         0.750  \n",
      "1         0.129  \n",
      "2         0.978  \n",
      "3         0.431  \n",
      "4         0.926  \n",
      "5         0.059  \n",
      "6         0.963  \n",
      "7         0.854  \n",
      "8         0.937  \n",
      "9         0.779  \n",
      "10        0.945  \n",
      "11        0.855  \n",
      "12        0.506  \n",
      "13        0.174  \n",
      "0.5128311580049454 7.149649794418069e-121\n",
      "   y       ate          p_val\n",
      "0  y  0.512831  7.149650e-121\n"
     ]
    }
   ],
   "source": [
    "# 如果你的连续变量特别skew，比如90%percentile 之外才有数，建议用自定义分桶来分连续变量\n",
    "\n",
    "\n",
    "# STEP 1: 第一步，初始化；initialize matching object\n",
    "match_obj_cem = matching(data = df, \n",
    "                       y = ['y'],\n",
    "                       T = 'treatment', \n",
    "                       X = ['c_1','d_1','d_3'],\n",
    "                       id = 'user_id')\n",
    "\n",
    "# STEP 2：第二步，粗粒度匹配；coarsened exact matching\n",
    "match_obj_cem.cem(n_bins = 10, \n",
    "                  \n",
    "                  # 连续变量c_1按照断点被分成了5个bin->[-inf,-1),[-1, 0.3), [0.3, 0.6), [0.6, 2),[2,inf]\n",
    "                  break_points = {'c_1': [-1, 0.3, 0.6, 2]}, \n",
    "                  \n",
    "                  # 离散变量d_1按照枚举值分成了3个bin，本来有5个bin\n",
    "                  cluster_criteria = {'d_1': [['apple','pear'],['cat','dog'],['bee']],\n",
    "                                      'd_3': [['0.0','1.0','2.0'],\n",
    "                                                ['3.0','4.0','5.0'],\n",
    "                                                ['6.0','7.0','8.0','9.0']]},\n",
    "                  k2k = True) # k2k: 如果匹配出的结果是实验组样本N1>对照组N2，在实验组样本中随机抽样N2个对照组样本，使得样本数均衡\n",
    "\n",
    "\n",
    "# STEP 3: 第三步，匹配后的平衡性检验；balance check after CEM\n",
    "print(match_obj_cem.balance_check(include_discrete=True))\n",
    "#         匹配的结果放在这个dataframe中，你可以后续继续用于其他的估计方法，比如OLS求ATE\n",
    "Y = match_obj_cem.df_out_final['y']\n",
    "X = match_obj_cem.df_out_final['treatment']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "print(results.params['treatment'],results.pvalues['treatment'])\n",
    "\n",
    "\n",
    "# STEP 4: 第四步，直接计算ATE\n",
    "print(match_obj_cem.ate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4dfcb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c61cd90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff2c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83208d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
